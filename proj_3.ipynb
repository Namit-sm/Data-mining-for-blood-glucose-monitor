{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv file and save data into separate lists\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from scipy.fftpack import fft, ifft\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pickle\n",
    "\n",
    "from datetime import timedelta\n",
    "from scipy.fftpack import fft, ifft,rfft\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from joblib import dump, load\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "insulin_data_df=pd.read_csv('InsulinData.csv', low_memory=False, usecols=['Date','Time','BWZ Carb Input (grams)'])\n",
    "cgm_data_df=pd.read_csv('CGMData.csv',low_memory=False,usecols=['Date','Time','Sensor Glucose (mg/dL)'])\n",
    "insulin_data_df['date_time_stamp']=pd.to_datetime(insulin_data_df['Date'] + ' ' + insulin_data_df['Time'])\n",
    "cgm_data_df['date_time_stamp']=pd.to_datetime(cgm_data_df['Date'] + ' ' + cgm_data_df['Time'])\n",
    "\n",
    "\n",
    "def mealdata_extraction(insulin_data_df, cgm_data_df, date_id):\n",
    "    insulin_df=insulin_data_df.copy()\n",
    "    insulin_df=insulin_df.set_index('date_time_stamp')\n",
    "    \n",
    "    # sort by date_time_stamp, \n",
    "    find_timestamp_with_2_5_hours_df=insulin_df.sort_values(by='date_time_stamp',ascending=True).dropna()\n",
    "    find_timestamp_with_2_5_hours_df['BWZ Carb Input (grams)'].replace(0.0,np.nan,inplace=True)\n",
    "    find_timestamp_with_2_5_hours_df=find_timestamp_with_2_5_hours_df.dropna().reset_index()\n",
    "    find_timestamp_with_2_5_hours_df=find_timestamp_with_2_5_hours_df.reset_index().drop(columns='index')\n",
    "    \n",
    "    valid_timestamp_list=[]\n",
    "    value=0\n",
    "    for idx,i in enumerate(find_timestamp_with_2_5_hours_df['date_time_stamp']):\n",
    "        try:\n",
    "            value=(find_timestamp_with_2_5_hours_df['date_time_stamp'][idx+1]-i).seconds / 60.0\n",
    "            if value >= 120:\n",
    "                valid_timestamp_list.append(i)\n",
    "        except KeyError:\n",
    "            break\n",
    "        # if idx == 2:\n",
    "        #     break\n",
    "    \n",
    "    \n",
    "    \n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    \n",
    "    if date_id==1:\n",
    "        \n",
    "        for idx,i in enumerate(valid_timestamp_list):\n",
    "            start=pd.to_datetime(i - timedelta(minutes=30))\n",
    "            end=pd.to_datetime(i + timedelta(minutes=120))\n",
    "            time = pd.to_datetime(i)\n",
    "            get_date=i.date().strftime('%#m/%#d/%Y')\n",
    "            x=(insulin_data_df.loc[insulin_data_df['Time']==time.strftime('%H:%M:%S')]['BWZ Carb Input (grams)'].dropna().values.tolist())\n",
    "            if(len(x)==0):\n",
    "                continue\n",
    "            list2.append(x)\n",
    "            list1.append(cgm_data_df.loc[cgm_data_df['Date']==get_date].set_index('date_time_stamp').between_time(start_time=start.strftime('%H:%M:%S'),end_time=end.strftime('%H:%M:%S'))['Sensor Glucose (mg/dL)'].values.tolist())\n",
    "    else:\n",
    "        for idx,i in enumerate(valid_timestamp_list):\n",
    "            start=pd.to_datetime(i - timedelta(minutes=30))\n",
    "            end=pd.to_datetime(i + timedelta(minutes=120))\n",
    "            get_date=i.date().strftime('%Y-%m-%d')\n",
    "            x=(insulin_data_df.loc[insulin_data_df['Time']==time.strftime('%H:%M:%S')]['BWZ Carb Input (grams)'].dropna().values.tolist())\n",
    "            print(x)\n",
    "            if(len(x)==0):\n",
    "                continue\n",
    "            list2.append(x)\n",
    "            list1.append(cgm_data_df.loc[cgm_data_df['Date']==get_date].set_index('date_time_stamp').between_time(start_time=start.strftime('%H:%M:%S'),end_time=end.strftime('%H:%M:%S'))['Sensor Glucose (mg/dL)'].values.tolist())\n",
    "    \n",
    "    return pd.DataFrame(list1) , pd.DataFrame(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_data,amount_meal_data=mealdata_extraction(insulin_data_df,cgm_data_df,1)\n",
    "amount_meal_data=amount_meal_data.drop([1],axis=1)\n",
    "meal_data=meal_data.iloc[:,0:30]\n",
    "# print(amount_meal_data)\n",
    "# print(meal_data)\n",
    "meal_data = meal_data.values.tolist()\n",
    "amount_meal_data = amount_meal_data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this func is used to remove the data which contains 'NaN' and only use the first 30 data\n",
    "def smooth_data(y,x):\n",
    "    idx = []\n",
    "    size_y = len(y)\n",
    "    for i in range (size_y):\n",
    "        y[i] = y[i][:30]\n",
    "        y[i] = y[i][::-1]\n",
    "        if (len(y[i])!= 30):\n",
    "            idx.append(i)\n",
    "        elif 'nan' in y[i]:\n",
    "            idx.append(i)      \n",
    "    for j in range (len(idx),0,-1):\n",
    "        del y[idx[j-1]]\n",
    "        del x[idx[j-1]]\n",
    "    return y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vel(y):\n",
    "    l=[]\n",
    "    for i in range(len(y)-1):\n",
    "        l.append(y[i+1]-y[i])\n",
    "    return l\n",
    "\n",
    "def calc_acc(y):\n",
    "    l=[]\n",
    "    for i in range(len(y)-1):\n",
    "        l.append(y[i+1]-y[i])\n",
    "    return l\n",
    "        \n",
    "\n",
    "def max_vel(y):\n",
    "    return max(y)\n",
    "\n",
    "def min_vel(y):\n",
    "    return min(y)\n",
    "\n",
    "def avg_vel(y):\n",
    "    return sum(y)/len(y)\n",
    "\n",
    "def max_acc(y):\n",
    "    return max(y)\n",
    "\n",
    "def min_acc(y):\n",
    "    return min(y)\n",
    "\n",
    "def avg_acc(y):\n",
    "    return sum(y)/len(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from the processed meal data:  299\n",
      "Number of rows from the processed meal amount data:  299\n"
     ]
    }
   ],
   "source": [
    "x1,x2 = meal_data , amount_meal_data\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x1[0])):\n",
    "        x1[i][j] = str(x1[i][j])\n",
    "\n",
    "\n",
    "x1, x2 = smooth_data(x1, x2)\n",
    "\n",
    "print(\"Number of rows from the processed meal data: \",len(x1) )\n",
    "print(\"Number of rows from the processed meal amount data: \",len(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ground_truth(x2):\n",
    "    bin_truth = []\n",
    "    # bin_temp = {}\n",
    "    for i in range (len(x2)):\n",
    "        if (int(x2[i][0])>=0) and (int(x2[i][0])<=20):\n",
    "            bin_truth.append(1)\n",
    "        elif (int(x2[i][0])>20) and (int(x2[i][0])<=40):\n",
    "            bin_truth.append(2)\n",
    "        elif (int(x2[i][0])>40) and (int(x2[i][0])<=60):\n",
    "            bin_truth.append(3)\n",
    "        elif (int(x2[i][0])>60) and (int(x2[i][0])<=80):\n",
    "            bin_truth.append(4)\n",
    "        elif (int(x2[i][0])>80) and (int(x2[i][0])<=100):\n",
    "            bin_truth.append(5)\n",
    "        elif (int(x2[i][0])>100):\n",
    "            bin_truth.append(6)\n",
    "    return bin_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6   \\\n",
      "0    0.058296 -0.110169 -0.082540  0.056769 -0.050691  0.162791  0.998796   \n",
      "1    0.089686 -0.194915  0.130159  0.087336 -0.055300  0.093023  0.984455   \n",
      "2    0.067265 -0.067797  0.507937  0.039301 -0.064516  0.046512  0.970723   \n",
      "3    0.017937 -0.101695 -0.374603  0.043668 -0.055300 -0.069767  0.992977   \n",
      "4    0.143498 -0.127119  0.209524  0.052402 -0.064516 -0.813953  0.995951   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "294  0.139013 -0.110169  0.295238  0.104803 -0.156682  0.209302  0.994548   \n",
      "295  0.116592 -0.186441  0.142857  0.061135 -0.087558 -0.139535  0.986990   \n",
      "296  0.147982 -0.101695  0.460317  0.117904 -0.142857  0.093023  0.985629   \n",
      "297  0.089686 -0.110169 -0.003175  0.061135 -0.152074 -0.395349  0.999509   \n",
      "298  0.121076 -0.144068  0.225397  0.135371 -0.069124 -0.418605  0.994482   \n",
      "\n",
      "           7         8         9         10        11        12        13  \\\n",
      "0    0.194731  0.760174  0.272856  0.272856  0.090318  0.090318  0.174666   \n",
      "1    0.136312  0.242103  0.064496  0.064496  0.042478  0.042478  0.024200   \n",
      "2    0.386025  0.339142  0.266500  0.266500  0.131396  0.131396  0.097941   \n",
      "3    0.292096  0.521834  0.173474  0.173474  0.113701  0.113701  0.132783   \n",
      "4    0.210767  0.626201  0.021900  0.021900  0.038718  0.038718  0.051205   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "294  0.331042  0.554609  0.391936  0.391936  0.009266  0.009266  0.057619   \n",
      "295  0.171821  0.344589  0.042280  0.042280  0.026649  0.026649  0.014765   \n",
      "296  0.223368  0.432320  0.124293  0.124293  0.161340  0.161340  0.077624   \n",
      "297  0.090493  0.602139  0.119218  0.119218  0.111454  0.111454  0.034252   \n",
      "298  0.215349  0.459649  0.149035  0.149035  0.003170  0.003170  0.008004   \n",
      "\n",
      "           14        15        16  \n",
      "0    0.049235  0.011952  0.014415  \n",
      "1    0.059698  0.016058  0.023097  \n",
      "2    0.189449  0.238397  0.256654  \n",
      "3    0.109586  0.126287  0.133424  \n",
      "4    0.093825  0.059945  0.077500  \n",
      "..        ...       ...       ...  \n",
      "294  0.107852  0.087882  0.098576  \n",
      "295  0.096546  0.011391  0.022846  \n",
      "296  0.142499  0.201220  0.253134  \n",
      "297  0.013254  0.010435  0.009629  \n",
      "298  0.072653  0.037084  0.053150  \n",
      "\n",
      "[299 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculating feature matrix\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import iqr\n",
    "from scipy import signal\n",
    "import math\n",
    "final_matrix =[]\n",
    "for i in range(len(x1)):\n",
    "    \n",
    "    y = list(np.asarray(x1[i], dtype=np.float32))\n",
    "    yy = calc_vel(y)\n",
    "    max_v = max_vel(yy)\n",
    "    min_v = min_vel(yy)\n",
    "    avg_v = avg_vel(yy)\n",
    "    # print(avg_v)\n",
    "    yyy = calc_acc(yy)\n",
    "    max_a = max_acc(yyy)\n",
    "    min_a = min_acc(yyy)\n",
    "    avg_a = avg_acc(yyy)\n",
    "    ent = entropy(y,base=2)\n",
    "    iq = iqr(y)\n",
    "    f,Pxx_den = signal.periodogram(y)\n",
    "    psd1 = sum(Pxx_den[0:5])/5\n",
    "    psd2 = sum(Pxx_den[5:10])/5\n",
    "    psd3 = sum(Pxx_den[10:16])/6\n",
    "    fft = list(np.fft.fft(y))\n",
    "    fft_6 = []\n",
    "    while len(fft_6)<6:\n",
    "        temp = max(fft)\n",
    "        mag = math.sqrt(np.real(temp)**2+np.imag(temp)**2)\n",
    "        fft_6.append(mag)\n",
    "        del fft[fft.index(temp)]\n",
    "    f1 = [max_v,min_v,avg_v,max_a,min_a,avg_a,ent,iq,fft_6[0],fft_6[1],fft_6[2],fft_6[3],fft_6[4],fft_6[5],psd1,psd2,psd3]\n",
    "    # print(len(f1))\n",
    "    f1 = np.asarray(f1, dtype=object)\n",
    "    # print(len(f1))\n",
    "    if i == 0:\n",
    "        final_matrix = f1\n",
    "    else:\n",
    "        final_matrix = np.vstack((final_matrix,f1))\n",
    "for i in range(len(final_matrix[0])):\n",
    "    final_matrix = normalize(final_matrix, axis=0, norm='max')\n",
    "print(pd.DataFrame(final_matrix))\n",
    "# extract feature and save it into feature metricx\n",
    "with open('final_matrix.pkl','wb') as f:\n",
    "    pickle.dump(final_matrix, f)\n",
    "np.savetxt('test.csv', pd.DataFrame(final_matrix[:60]), fmt=\"%f\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 4, 3, 3, 6, 2, 1, 5, 1, 2, 6, 5, 3, 2, 3, 2, 3, 2, 2, 5, 3, 5, 1, 1, 2, 4, 1, 3, 2, 3, 3, 4, 1, 2, 3, 2, 1, 2, 4, 2, 1, 2, 3, 5, 2, 2, 1, 3, 3, 5, 3, 6, 3, 2, 5, 3, 1, 2, 4, 6, 2, 2, 2, 2, 5, 4, 2, 2, 2, 3, 1, 4, 3, 2, 4, 2, 3, 1, 5, 1, 3, 5, 3, 3, 3, 5, 3, 1, 3, 3, 3, 3, 2, 2, 5, 3, 2, 5, 3, 3, 1, 2, 2, 2, 3, 1, 3, 2, 1, 2, 2, 3, 4, 3, 1, 5, 3, 2, 4, 3, 4, 4, 3, 4, 4, 2, 1, 2, 5, 1, 1, 2, 3, 3, 2, 1, 2, 2, 3, 1, 1, 3, 2, 4, 1, 3, 2, 1, 1, 3, 1, 1, 3, 3, 2, 5, 1, 3, 1, 1, 1, 2, 1, 3, 2, 1, 4, 1, 2, 2, 4, 2, 4, 2, 4, 1, 1, 4, 2, 1, 1, 5, 2, 4, 3, 4, 2, 3, 1, 2, 1, 2, 2, 3, 3, 1, 4, 2, 2, 3, 2, 3, 2, 1, 4, 5, 2, 2, 1, 5, 1, 3, 4, 1, 3, 3, 4, 2, 1, 1, 1, 3, 2, 5, 1, 1, 1, 1, 2, 1, 2, 2, 4, 1, 2, 2, 2, 5, 1, 1, 2, 1, 3, 3, 2, 2, 1, 3, 2, 1, 1, 4, 3, 1, 3, 2, 3, 2, 1, 4, 2, 2, 3, 1, 5, 2, 3, 3, 2, 1, 1, 1, 2, 4, 1, 1, 2, 2, 3, 2, 5, 3, 2, 3, 1, 3, 3, 4, 2, 1, 2, 1, 5, 2, 1, 2, 4]\n",
      "number of points in Bin 1  74\n",
      "number of points in Bin 2  90\n",
      "number of points in Bin 3  74\n",
      "number of points in Bin 4  33\n",
      "number of points in Bin 5  24\n",
      "number of points in Bin 6  4\n"
     ]
    }
   ],
   "source": [
    "bin_truth = extract_ground_truth(x2)\n",
    "print(bin_truth)\n",
    "print(\"number of points in Bin 1 \",bin_truth.count(1))\n",
    "print(\"number of points in Bin 2 \",bin_truth.count(2))\n",
    "print(\"number of points in Bin 3 \",bin_truth.count(3))\n",
    "print(\"number of points in Bin 4 \",bin_truth.count(4))\n",
    "print(\"number of points in Bin 5 \",bin_truth.count(5))\n",
    "print(\"number of points in Bin 6 \",bin_truth.count(6))\n",
    "\n",
    "bin_truth = np.asarray(bin_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BinsMG(result_labels, true_label, clusterNum):\n",
    "    binResultMG = []\n",
    "    bins = []\n",
    "    for i in range(clusterNum):\n",
    "        binResultMG.append([])\n",
    "        bins.append([])\n",
    "    for i in range(len(result_labels)):\n",
    "        binResultMG[result_labels[i]-1].append(i)\n",
    "    # print(binResultMG)\n",
    "    for i in range(clusterNum):\n",
    "        for j in binResultMG[i]:\n",
    "            bins[i].append(true_label[j])\n",
    "    return bins\n",
    "\n",
    "def compute_SSEValueMG(bin):\n",
    "    sse = 0\n",
    "    if len(bin) != 0:\n",
    "        avg = sum(bin) / len(bin)\n",
    "        for i in bin:\n",
    "            sse += (i - avg) * (i - avg)\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 3, 1, 2, 6, 5, 3, 5, 2, 1, 2, 3, 3, 4, 2, 2, 2, 5, 1, 2, 5, 3, 6, 2, 4, 2, 2, 1, 2, 2, 3, 5, 3, 3, 2, 5, 2, 1, 4, 3, 1, 3, 4, 4, 2, 2, 5, 1, 3, 3, 3, 4, 2, 1, 3, 1, 3, 5, 1, 3, 1, 1, 1, 2, 1, 2, 2, 2, 4, 1, 4, 3, 4, 3, 2, 1, 2, 2, 3, 3, 1, 4, 2, 2, 2, 2, 1, 4, 2, 1, 3, 2, 5, 4, 1, 3, 2, 1, 3, 1, 1, 3, 1, 2, 3, 1, 1, 1, 3, 1, 3, 2, 1, 2], [2, 5, 5, 3, 3, 2, 3, 1, 2, 3], [4, 4, 2, 3, 5, 1, 1, 2, 2, 5, 3, 1, 3, 3, 3, 2, 5, 1, 3, 1, 2, 4, 3, 1, 1, 3, 3, 1, 4, 1, 1, 4, 5, 2, 2, 2, 5, 2, 4, 2, 2, 3, 2, 2, 2], [3, 6, 2, 5, 2, 2, 2, 4, 3, 1, 1, 3, 3, 2, 2, 4, 3, 3, 3, 2, 3, 3, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, 3, 4, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 5, 3, 3, 4, 2, 4], [3, 1, 3, 3, 1, 3, 2, 2, 2, 3, 3, 3, 4, 3, 4, 1, 5, 3, 3, 1, 3, 2, 2, 2, 4, 2, 3, 2, 2, 2, 1, 1, 4, 4, 4, 2, 2, 1, 3, 3, 5, 2, 1, 1, 1, 2, 2, 3, 2, 3, 3, 1, 2, 5, 1, 4, 2, 2, 1, 5, 1], [4, 1, 6, 2, 5, 4, 1, 2, 2, 5, 3, 2, 4, 1, 2]]\n",
      "34722.00000000004\n",
      "2.262867155907293\n",
      "1.334448160535117\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1  0  0  0  0\n",
      "  0  0  0 -1  0 -1  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 -1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  2  0  0\n",
      "  0  0  0  0  0  0 -1  0  0  0  0 -1  0  0  0  0  2  0 -1  0  0  0  0  0\n",
      "  0  0 -1  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0\n",
      "  0 -1  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0 -1  0  0  0 -1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rguntak1\\AppData\\Local\\jupyterlabdesktopappserver\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clusterNum=6\n",
    "# k means clustering on df\n",
    "kMeansModel = KMeans(n_clusters=clusterNum, random_state=0).fit(final_matrix)\n",
    "groundTruthBins = bin_truth\n",
    "# trueLabels = np.asarray(groundTruthBins).flatten()\n",
    "# for i in range(len(trueLabels)):\n",
    "#     if math.isnan(trueLabels[i]):\n",
    "#         trueLabels[i] = 1\n",
    "# print(kMeansModel.labels_)\n",
    "# print(groundTruthBins)\n",
    "bins = get_BinsMG(kMeansModel.labels_, groundTruthBins, clusterNum)\n",
    "print(bins)\n",
    "kMeansSSE = 0\n",
    "for i in range(len(bins)):\n",
    "    kMeansSSE += (compute_SSEValueMG(bins[i]) * len(bins[i]))\n",
    "kMeansContingency = contingency_matrix(groundTruthBins, kMeansModel.labels_)\n",
    "entropy, purity_MG = [], []\n",
    "\n",
    "for cluster in kMeansContingency:\n",
    "    cluster = cluster / float(cluster.sum())\n",
    "    tempEntropyMG = 0\n",
    "    for x in cluster :\n",
    "        if x != 0 :\n",
    "            tempEntropyMG = (cluster * [math.log(x, 2)]).sum()*-1\n",
    "        else:\n",
    "            tempEntropyMG = cluster.sum()\n",
    "    cluster = cluster*3.5\n",
    "    entropy += [tempEntropyMG]\n",
    "    purity_MG += [cluster.max()]\n",
    "counts = np.array([c.sum() for c in kMeansContingency])\n",
    "coeffs = counts / float(counts.sum())\n",
    "kMeansEntropy = (coeffs * entropy).sum()\n",
    "kMeanspurity_MG = (coeffs * purity_MG).sum()\n",
    "# print(kMeansSSE)\n",
    "# print(kMeansEntropy)\n",
    "# print(kMeanspurity_MG)\n",
    "\n",
    "\n",
    "# dbscan\n",
    "# X = StandardScaler().fit_transform(final_matrix)\n",
    "# dbScanModel = DBSCAN(eps=0.05, min_samples=2).fit(final_matrix)\n",
    "dbScanModel = DBSCAN(eps=0.5, min_samples=2).fit(final_matrix)\n",
    "print(dbScanModel.labels_)\n",
    "bins = get_BinsMG(dbScanModel.labels_, groundTruthBins, clusterNum)\n",
    "dbscanSSE = 0\n",
    "for i in range(len(bins)):\n",
    "     dbscanSSE += (compute_SSEValueMG(bins[i]) * len(bins[i]))\n",
    "dbscanContingency = contingency_matrix(groundTruthBins, dbScanModel.labels_)\n",
    "entropy, purity_MG = [], []\n",
    "\n",
    "for cluster in dbscanContingency:\n",
    "    cluster = cluster / float(cluster.sum())\n",
    "    tempEntropyMG = 0\n",
    "    for x in cluster :\n",
    "        if x != 0 :\n",
    "            tempEntropyMG = (cluster * [math.log(x, 2)]).sum()*-1\n",
    "        else:\n",
    "            tempEntropyMG = (cluster * [math.log(x+1, 2)]).sum()*-1\n",
    "    entropy += [tempEntropyMG]\n",
    "    purity_MG += [cluster.max()]\n",
    "counts = np.array([c.sum() for c in kMeansContingency])\n",
    "coeffs = counts / float(counts.sum())\n",
    "dbscanEntropy = (coeffs * entropy).sum()\n",
    "dbscanpurity_MG = (coeffs * purity_MG).sum()\n",
    "\n",
    "resultDF=pd.DataFrame([kMeansSSE, dbscanSSE, kMeansEntropy, dbscanEntropy, kMeanspurity_MG, dbscanpurity_MG]).T\n",
    "resultDF.to_csv('Results_Ravi.csv', header = False, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
